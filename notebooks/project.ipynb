{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07eb777",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85cce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6400a",
   "metadata": {},
   "source": [
    "### Seed Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620cdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading bars on notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed\n",
    "SEED = 385433  # my G number\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ad379",
   "metadata": {},
   "source": [
    "### Read in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a03c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ankleboot: 100%|█████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 4708.65it/s]\n",
      "Loading bag: 100%|███████████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 4394.36it/s]\n",
      "Loading coat: 100%|██████████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 3842.03it/s]\n",
      "Loading dress: 100%|█████████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 3881.49it/s]\n",
      "Loading pullover: 100%|██████████████████████████████████████████████████████████| 7000/7000 [00:01<00:00, 3992.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define dataset path\n",
    "DATASET_PATH = \"fashion\"\n",
    "# CATEGORIES = ['ankleboot', 'bag']\n",
    "CATEGORIES = ['ankleboot', 'bag', 'coat', 'dress', 'pullover']#, 'sandal', 'shirt', 'sneaker', 'trouser', 'tshirt-top']\n",
    "\n",
    "# Load images and labels with progress bar\n",
    "X, y = [], []\n",
    "for label, category in enumerate(CATEGORIES):\n",
    "    folder_path = os.path.join(DATASET_PATH, category)\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in tqdm(files, desc=f\"Loading {category}\"):\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "        img_resized = img.resize((28, 28))  # Resize to 28x28\n",
    "        X.append(np.array(img_resized).flatten())  # Flatten images\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print('Read in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a017ac0",
   "metadata": {},
   "source": [
    "### Split Dataset into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6996e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Data: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 44.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (22400, 784) (22400,)\n",
      "Validation Set Shape: (5600, 784) (5600,)\n",
      "Test Set Shape: (7000, 784) (7000,)\n",
      "Class Distribution in Training Set:\n",
      "0    0.2\n",
      "2    0.2\n",
      "1    0.2\n",
      "3    0.2\n",
      "4    0.2\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation, and test sets with progress bar\n",
    "print(\"Splitting dataset...\")\n",
    "with tqdm(total=2, desc=\"Splitting Data\") as pbar:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=True, stratify=y)\n",
    "    pbar.update(1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, shuffle=True, stratify=y_train)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Check dataset distribution\n",
    "print(\"Training Set Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation Set Shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test Set Shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Class Distribution in Training Set:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86c829",
   "metadata": {},
   "source": [
    "### Define Models to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44a6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models = {\n",
    "    \"SVM\": SVC(kernel='rbf', random_state=SEED),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=SEED)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cea6c",
   "metadata": {},
   "source": [
    "# Train Models and Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387544e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('SVM', SVC(random_state=385433)), ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=385433)), ('kNN', KNeighborsClassifier()), ('Random Forest', RandomForestClassifier(random_state=385433))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-21 16:20:50\n",
      "Checking model training times...\n",
      "SVM took 0.04 seconds on a small subset.\n",
      "Logistic Regression took 0.72 seconds on a small subset.\n",
      "kNN took 0.00 seconds on a small subset.\n",
      "Random Forest took 0.84 seconds on a small subset.\n",
      "Training Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training Progress:   0%|                                                                         | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting SVM:   0%|                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Fitting SVM: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:42<00:00, 42.32s/it]\u001b[A\n",
      "                                                                                                                       \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM training took 42.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "print(\"Checking model training times...\")\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train[:500], y_train[:500])  # Train on small subset\n",
    "    end_time = time.time()\n",
    "    print(f\"{name} took {end_time - start_time:.2f} seconds on a small subset.\")\n",
    "# Train models and evaluate performance\n",
    "results = {}\n",
    "cross_val_results = {}\n",
    "\n",
    "print(\"Training Models...\")\n",
    "\n",
    "with tqdm(total=len(models), desc=\"Training Progress\", leave=True) as pbar:\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "\n",
    "        start_time = time.time()  # Track time\n",
    "\n",
    "        # Train the model with a progress indicator\n",
    "        for i in tqdm(range(1), desc=f\"Fitting {name}\", leave=False):\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"{name} training took {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Cross-validation with progress bar\n",
    "        cross_val_scores = []\n",
    "        for score in tqdm(cross_val_score(model, X_train, y_train, cv=3), desc=f\"Cross-validation {name}\", leave=False):\n",
    "            print(score)\n",
    "            cross_val_scores.append(score)\n",
    "\n",
    "        cross_val_score_avg = np.mean(cross_val_scores)\n",
    "\n",
    "        results[name] = accuracy_score(y_val, y_pred)\n",
    "        cross_val_results[name] = cross_val_score_avg\n",
    "\n",
    "        print(f\"{name} Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "        pbar.update(1)  # Update the outer progress bar\n",
    "\n",
    "print(\"\\nModel training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969a83",
   "metadata": {},
   "source": [
    "### Compare Model Performance (Accuracy and Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Results\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
    "cross_val_df = pd.DataFrame.from_dict(cross_val_results, orient='index', columns=['Cross-Val Accuracy'])\n",
    "print(\"\\nModel Performance:\")\n",
    "print(results_df)\n",
    "print(\"\\nCross-Validation Performance:\")\n",
    "print(cross_val_df)\n",
    "\n",
    "# Plot model accuracy comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=results_df.index, y=results_df[\"Accuracy\"], palette=\"viridis\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Plot cross-validation accuracy comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=cross_val_df.index, y=cross_val_df[\"Cross-Val Accuracy\"], palette=\"coolwarm\")\n",
    "plt.title(\"Cross-Validation Accuracy Comparison\")\n",
    "plt.ylabel(\"Cross-Val Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2e51a",
   "metadata": {},
   "source": [
    "# Evaluate the Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f69004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Best Model on Test Set\n",
    "best_model_name = results_df[\"Accuracy\"].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
